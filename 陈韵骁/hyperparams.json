{
    "batch_size": 128,
    "learning_rate": 0.0005,
    "weight_decay": 0.0001,
    "epochs": 15,
    "optimizer": "AdamW",
    "scheduler": "StepLR",
    "step_size": 5,
    "gamma": 0.1,
    "model_architecture": "ImprovedVGG(\n  (features): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): CBAM(\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Linear(in_features=32, out_features=2, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=2, out_features=32, bias=True)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n        (sigmoid): Sigmoid()\n      )\n    )\n    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU()\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Dropout(p=0.25, inplace=False)\n    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU()\n    (12): CBAM(\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Linear(in_features=64, out_features=4, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=4, out_features=64, bias=True)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n        (sigmoid): Sigmoid()\n      )\n    )\n    (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (15): ReLU()\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Dropout(p=0.25, inplace=False)\n    (18): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU()\n    (21): CBAM(\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Linear(in_features=128, out_features=8, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=8, out_features=128, bias=True)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n        (sigmoid): Sigmoid()\n      )\n    )\n    (22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (23): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (24): ReLU()\n    (25): AdaptiveAvgPool2d(output_size=(3, 3))\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1152, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=512, out_features=10, bias=True)\n  )\n)",
    "data_augmentation": {
        "RandomHorizontalFlip": true,
        "RandomRotation": 10
    },
    "normalization": {
        "mean": [
            0.5
        ],
        "std": [
            0.5
        ]
    }
}